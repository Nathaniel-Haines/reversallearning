dilemma.trials.record<-complete.dt[Condition==1,.N,.(subid,runid,Motivation)][,.(Subjects=.N,TrialsPerSubject=mean(N)),.(Motivation,runid)]
knitr::kable(merge(all.trials.record,dilemma.trials.record,by.x=c("Motivation","runid"),by.y=c("Motivation","runid","Subjects"),
suffixes = c(" All Trials", " Dilemma Trials")))
all.trials.record<-complete.dt[,.N,.(subid,runid,Motivation)][,.(Subjects=.N,TrialsPerSubject=mean(N)),.(Motivation,runid)]
dilemma.trials.record<-complete.dt[Condition==1,.N,.(subid,runid,Motivation)][,.(Subjects=.N,TrialsPerSubject=mean(N)),.(Motivation,runid)]
knitr::kable(merge(all.trials.record,dilemma.trials.record,by.x=c("Motivation","runid","Subjects"),by.y=c("Motivation","runid","Subjects"),
suffixes = c(" All Trials", " Dilemma Trials")))
fit4 <- vb(base.model, data = dataList,
pars = c("mu_alpha", "mu_beta",
"sigma",
"alpha", "beta",
"log_lik", "y_hat"),
adapt_engaged = F, eta = 1)
rm(list = ls())
library(rstan)
library(loo)
# Read in raw data
rawdata.all <- read.table("../data/all_subjs_datacomplete_all.txt", header = T)
rawdata.group2 <- subset(rawdata.all, subid<155 & choice != 0 & cue != 0 & RiskCat==2)
length(unique(rawdata.group2$subid))
rawdata.group4 <- subset(rawdata.all, subid<315 & choice != 0 & cue != 0 & RiskCat==3)
length(unique(rawdata.group4$subid))
rawdata<-rbind(rawdata.group2,rawdata.group4)
rawdata.rewardonly<-subset(rawdata.all, subid<211 & choice != 0 & cue != 0 & RiskCat %in% c(2,3) & Motivation=="reward")
length(unique(rawdata.rewardonly$subid))
data.to.use<-rawdata.rewardonly
subidgroup<-unique(data.to.use[,c("subid","RiskCat")])
subjList <- subidgroup$subid  # list of subjects x blocks
subjGroupList<-subidgroup$RiskCat #list of subject group
numSubjs <- length(subjList)  # number of subjects
Gr_N <- length(unique(subjGroupList))#number of groups
Tsubj    <- as.vector( rep( 0, numSubjs ) ) # number of trials for each subject
N_cues   <- as.vector( rep( 0, numSubjs ) ) # number of trials for each subject
for ( i in 1:numSubjs )  {
curSubj   <- subjList[ i ]
Tsubj[i]  <- sum( data.to.use$subid == curSubj )  # Tsubj[N]
N_cues[i] <- length(unique(data.to.use$cue))
}
maxTrials <- max(Tsubj)
choice  <- array(0, c(numSubjs, maxTrials) )
outcome <- array(0, c(numSubjs, maxTrials) )
cue     <- array(0, c(numSubjs, maxTrials) )
for (i in 1:numSubjs) {
#i<-numSubjs
curSubj      <- subjList[i]
useTrials    <- Tsubj[i]
tmp          <- subset(data.to.use, data.to.use$subid == curSubj)
choice[i, 1:useTrials]  <- tmp$choice
outcome[i, 1:useTrials] <- tmp$outcome
cue[i, 1:useTrials]     <- as.numeric(as.factor(tmp$cue))
}
dataList <- list(
N        = numSubjs,
T        = maxTrials,
Tsubj    = Tsubj,
subjGr  = subjGroupList,
N_cues   = N_cues - 1,
choice   = choice,
outcome  = outcome,
cue      = cue,
numPars  = 2
)
fit4 <- vb(base.model, data = dataList,
pars = c("mu_alpha", "mu_beta",
"sigma",
"alpha", "beta",
"log_lik", "y_hat"),
adapt_engaged = F, eta = 1)
base.model<- stan_model("stan/prl_ben_v3_orig.stan")
fit4 <- vb(base.model, data = dataList,
pars = c("mu_alpha", "mu_beta",
"sigma",
"alpha", "beta",
"log_lik", "y_hat"),
adapt_engaged = F, eta = 1)
traceplot(fit4)
stan_plot(fit4, "alpha", show_density = T)
loo(extract(fit4)$log_lik)
parVals <- extract(fit4)
pred <- reshape2::melt(apply(parVals$y_hat, c(2,3), mean))
names(pred) <- c("subjID", "trial", "pred")
new_pred <- pred[pred$pred!=0,]
all_data <- cbind(rawdata, new_pred)
base.model<- stan_model("stan/prl_ben_v3_orig.stan")
fit4 <- vb(base.model, data = dataList,
pars = c("mu_alpha", "mu_beta",
"sigma",
"alpha", "beta",
"log_lik", "y_hat"),
adapt_engaged = F, eta = 1)
source("util/get_cue_index_from_cum_freq.R")
data
ds
traceplot(fit)
fit <- vb(base.model, data = dataList,
pars = c("mu_alpha", "mu_beta",
"sigma",
"alpha", "beta",
"log_lik", "y_hat"),
adapt_engaged = F, eta = 1)
traceplot(fit)
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(rstan)
library(ggplot2)
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group")
rawdata$subid==curSubj
table(rawdata$RiskCat)
data.table(rawdata)
rawdata.dt<-data.table(rawdata)
rawdata.dt[subid==curSubj,RiskCat]
curSubjRiskCat<-rawdata.dt[subid==curSubj,RiskCat]
curSubjRiskCat[1]
curSubjRiskCat[1]==curSubjRiskCat
mylist<-list()
mylist("one")=c(1,2,3)
mylist["one"]=c(1,2,3)
mylist[["one"]]=c(1,2,3)
mylist
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
rawdata.dt
rawdata.dt[subid]
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
print(curSubjRiskCat)
subjGroup
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
source("fitGroupsV3OnegroupRun1.R")
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,c(2,3), model_to_use="prl_ben_v3_group",includeSubjGroup = TRUE)
source("fitGroupsV3OnegroupRun1.R")
fit<-lookupOrRunFit(run=1,2, model_to_use="double_update_rp",includeSubjGroup = FALSE)
fit<-lookupOrRunFit(run=1,2, model_to_use="double_update_rp",includeSubjGroup = FALSE)
fit<-lookupOrRunFit(run=1,2, model_to_use="double_update_rp",includeSubjGroup = FALSE)
fit<-lookupOrRunFit(run=1,2, model_to_use="double_update_rp",includeSubjGroup = FALSE)
setwd("~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning")
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/savehBayesInput.R')
setwd("~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files")
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(rstan)
library(ggplot2)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,2, model_to_use="double_update_rp",includeSubjGroup = FALSE,rp=c(1,2),model_rp_separately=TRUE,include_pain=FALSE)
file.exists(fit.fileid)
fit.fileid
fit.fileid
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,2, model_to_use="double_update_rp",includeSubjGroup = FALSE,rp=c(1,2),model_rp_separately=TRUE,include_pain=FALSE)
rp
paste0(c(1,2),collapse = T)
paste0(c(1,2),collapse = "")
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,groups_to_fit=2, model_to_use="double_update_rp",includeSubjGroup = FALSE,
rp=c(1,2),model_rp_separately=TRUE,include_pain=FALSE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,groups_to_fit=2, model_to_use="double_update_rp",includeSubjGroup = FALSE,
rp=c(1,2),model_rp_separately=TRUE,include_pain=FALSE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,groups_to_fit=2, model_to_use="double_update_rp",includeSubjGroup = FALSE,
rp=c(1,2),model_rp_separately=TRUE,include_pain=FALSE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
fit<-lookupOrRunFit(run=1,groups_to_fit=2, model_to_use="double_update_rp",includeSubjGroup = FALSE,
rp=c(1,2),model_rp_separately=TRUE,include_pain=FALSE)
fit_desc
fit.extracted<-rstan::extract(fit$fit)
learning.rate.estimate<-data.table(mean=fit.extracted$mu_alpha,
variance=fit.extracted$sigma[,1])
dim(fit.extracted$mu_alpha)
summary(fit.extracted)
dim(fit.extracted$sigma)
learning.rate.estimate_rew<-data.table(mean=fit.extracted$mu_alpha_rew,
variance=fit.extracted$sigma[,1,1])
View(learning.rate.estimate_rew)
inverse.temperature.estimate<-data.table(mean=fit.extracted$mu_beta_rew,
variance=fit.extracted$sigma[,1,2])
inverse.temperature.estimate.rew<-data.table(mean=fit.extracted$mu_beta_rew,
variance=fit.extracted$sigma[,1,2])
ggplot(learning.rate.estimate.rew,aes(x=mean,y=variance))+geom_point()
inverse.temperature.estimate.rew<-data.table(mean=fit.extracted$mu_beta_rew,
variance=fit.extracted$sigma[,1,2])
learning.rate.estimate.rew<-data.table(mean=fit.extracted$mu_alpha_rew,
variance=fit.extracted$sigma[,1,1])
inverse.temperature.estimate.rew<-data.table(mean=fit.extracted$mu_beta_rew,
variance=fit.extracted$sigma[,1,2])
ggplot(learning.rate.estimate.rew,aes(x=mean,y=variance))+geom_point()
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance))+geom_point()
learning.rate.estimate<-rbind(data.table(mean=fit.extracted$mu_alpha_rew,
variance=fit.extracted$sigma[,1,1],mode="reward"),
data.table(mean=fit.extracted$mu_alpha_pun,
variance=fit.extracted$sigma[,2,1],mode="punishment"))
inverse.temperature.estimate.pun<-rbind(data.table(mean=fit.extracted$mu_beta_rew,
variance=fit.extracted$sigma[,1,2],mode="reward"),
data.table(mean=fit.extracted$mu_beta_pun,
variance=fit.extracted$sigma[,2,2],mode="punishment"))
ggplot(learning.rate.estimate.rew,aes(x=mean,y=variance,fill=mode))+geom_point()
learning.rate.estimate<-rbind(data.table(mean=fit.extracted$mu_alpha_rew,
variance=fit.extracted$sigma[,1,1],mode="reward"),
data.table(mean=fit.extracted$mu_alpha_pun,
variance=fit.extracted$sigma[,2,1],mode="punishment"))
learning.rate.estimate
ggplot(learning.rate.estimate.rew,aes(x=mean,y=variance,fill=mode))+geom_point()
ggplot(learning.rate.estimate,aes(x=mean,y=variance,fill=mode))+geom_point()
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=mode))+geom_point()
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=mode))+geom_point()+
labs(title="Estimated population-level learning rates and variance for reward and punishment")
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=mode))+geom_point()+
labs(title="Estimated population-level learning rates and variance for reward and punishment\n(Run 1)")
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=mode))+geom_point()+
labs(title="Estimated population-level inverse temperature and variance for reward and punishment\n(Run 1)")
inverse.temperature.estimate.pun<-rbind(data.table(mean=fit.extracted$mu_beta_rew,
variance=fit.extracted$sigma[,1,2],mode="reward"),
data.table(mean=fit.extracted$mu_beta_pun,
variance=fit.extracted$sigma[,2,2],mode="punishment"))
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=mode))+geom_point()+
labs(title="Estimated population-level inverse temperature and variance for reward and punishment\n(Run 1)")
inverse.temperature.estimate<-rbind(data.table(mean=fit.extracted$mu_beta_rew,
variance=fit.extracted$sigma[,1,2],mode="reward"),
data.table(mean=fit.extracted$mu_beta_pun,
variance=fit.extracted$sigma[,2,2],mode="punishment"))
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=mode))+geom_point()+
labs(title="Estimated population-level inverse temperature and variance for reward and punishment\n(Run 1)")
learning.rate.estimate<-rbind(data.table(mean=fit.extracted$mu_alpha_rew,
variance=fit.extracted$sigma[,1,1],mode="reward"),
data.table(mean=fit.extracted$mu_alpha_pun,
variance=fit.extracted$sigma[,2,1],mode="punishment"))
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=mode))+geom_point()+
labs(title="Estimated population-level learning rates and variance for reward and punishment\n(Run 1)")
fit.RiskyMeth<-lookupOrRunFit(run=1,groups_to_fit=3, model_to_use="double_update_rp",includeSubjGroup = FALSE,
rp=c(1,2),model_rp_separately=TRUE,include_pain=FALSE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3OnegroupRun1.R')
source("fitGroupsV3OnegroupRun1.R")
fit.RiskyMeth<-lookupOrRunFit(run=1,groups_to_fit=3, model_to_use="double_update_rp",includeSubjGroup = FALSE,
rp=c(1,2),model_rp_separately=TRUE,include_pain=FALSE)
learning.rate.estimate.g2<-rbind(data.table(mean=fit.extracted$mu_alpha_rew,
variance=fit.extracted$sigma[,1,1],mode="reward",Group="RiskyNoMeth"),
data.table(mean=fit.extracted$mu_alpha_pun,
variance=fit.extracted$sigma[,2,1],mode="punishment",Group="RiskyNoMeth"))
inverse.temperature.estimate.g2<-rbind(data.table(mean=fit.extracted$mu_beta_rew,
variance=fit.extracted$sigma[,1,2],mode="reward",Group="RiskyNoMeth"),
data.table(mean=fit.extracted$mu_beta_pun,
variance=fit.extracted$sigma[,2,2],mode="punishment",Group="RiskyNoMeth"))
fit.RiskyMeth.extracted<-rstan::extract(fit.RiskyMeth$fit)
learning.rate.estimate<-rbind(learning.rate.estimate.g2,data.table(mean=fit.RiskyMeth.extracted$mu_alpha_rew,
variance=fit.RiskyMeth.extracted$sigma[,1,1],mode="reward",Group="RiskyMeth"),
data.table(mean=fit.RiskyMeth.extracted$mu_alpha_pun,
variance=fit.RiskyMeth.extracted$sigma[,2,1],mode="punishment",Group="RiskyMeth"))
inverse.temperature.estimate<-rbind(inverse.temperature.estimate.g2,data.table(mean=fit.RiskyMeth.extracted$mu_beta_rew,
variance=fit.RiskyMeth.extracted$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=fit.RiskyMeth.extracted$mu_beta_pun,
variance=fit.RiskyMeth.extracted$sigma[,2,2],mode="punishment",Group="RiskyMeth"))
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Estimated population-level inverse temperature and variance for reward and punishment\n(Run 1, Reward task)")
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Estimated population-level learning rate and variance for reward and punishment\n(Run 1)")
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Estimated population-level inverse temperature and variance for reward and punishment\n(Run 1, Reward task)")
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(rstan)
library(ggplot2)
source("fitGroupsV3Onegroup.R")
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(rstan)
library(ggplot2)
fit<-fitGroupsV3Onegroup(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE,
fastDebug = TRUE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
fit<-fitGroupsV3Onegroup(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE,
fastDebug = TRUE)
table(for_plot$subjID)
table(parVals$p_subjID)
dim(parVals)
summary(parVals)
dim(parVals$p_subjID)
table(parVals$p_subjID)
parVals$p_subjID[1:100]
plot(parVals$p_subjID==TRUE)
252252/41
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/Misc/plot_model.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
fit<-fitGroupsV3Onegroup(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE,
fastDebug = TRUE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/Misc/plot_model.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
fit<-fitGroupsV3Onegroup(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE,
fastDebug = TRUE)
parVals$y_hat
dim(parVals$y_hat)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
fit<-fitGroupsV3Onegroup(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE,
fastDebug = TRUE)
fit<-fitGroupsV3Onegroup(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE,
fastDebug = TRUE)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/fitGroupsV3Onegroup.R')
fit<-fitGroupsV3Onegroup(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE,
fastDebug = TRUE)
plot_model(fit.RiskyMeth)
plot_model(fit)
source('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/Misc/plot_model.R')
plot_model(fit)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/Misc/plot_model.R')
plot_model(fit)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/Misc/plot_model.R')
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/Misc/plot_model.R')
plot_model(fit)
plot_data <- for_plot %>%
group_by(subjID,cue_pos) %>%
summarize(actual_cor = mean(actual_correct, na.rm=T),
pred_cor = mean(all_pred_correct, na.rm=T),
# pred_low_q = quantile(all_pred_correct, probs = 0.025, na.rm=T),
# pred_high_q = quantile(all_pred_correct, probs = 0.975, na.rm=T),
se_cor = as.vector(Hmisc::binconf(x=sum(actual_correct,na.rm=T),n = length(actual_correct)))[1] - as.vector(Hmisc::binconf(x=sum(actual_correct,na.rm=T),n = length(actual_correct)))[2])
names(fit)
debugSource('~/GDrive/joint-modeling/reversal-learning/behavioral-analysis/reversallearning/nate_files/Misc/plot_model.R')
plot_model(fit)
HDIofMCMC
library(hBayesDM)
HDIofMCMC
fit.extracted<-rstan::extract(fit$fit)
fit.extracted$alpha_rew
dim(fit.extracted$alpha_rew)
HDIofMCMC(fit.extracted$mu_alpha_rew)
ggplot(fit.extracted$mu_alpha_rew)+geom_histogram(bins=10)
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverse.temperature.estimate.g2<-learningRateTable(fit.RiskyNoMeth.extracted)
fit.NoRiskyMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.extracted<-rstan::extract(fit.NoRiskyMeth$fit)
HDIofMCMC(fit.RiskyNoMeth.extracted$mu_alpha_rew)
HDIofMCMC(fit.RiskyNoMeth.extracted$mu_beta_rew)
rm(fit)
rm(fit.extracted)
rm(fit.NoRiskyMeth)
rm(fit.RiskyNoMeth.extracted)
source("fitGroupsV3Onegroup.R")
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_alpha_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_alpha_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverseTemperatureTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
fit.RiskyNoMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.NoRiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g2<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g2<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
#rm(fit.RiskyNoMeth.ex)
fit.RiskyMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyMeth.ex<-rstan::extract(fit.RiskyMeth$fit)
rm(fit.RiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g3<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g3<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
#rm(fit.RiskyMeth.ex)
learning.rate.estimate<-rbind(learning.rate.estimate.g2,learning.rate.estimate.g3)
inverse.temperature.estimate<-rbind(inverse.temperature.estimate.g2,inverse.temperature.estimate.g3)
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level learning rate and variance for reward and punishment\n(Both Runs)")
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level inverse temperature and variance for reward and punishment\n(Both Runs)")
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.NoRiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
rm(fit.RiskyMeth.ex)
rm(fit.RiskyNoMeth)
rm(fit.RiskyNoMeth.ex)
source("fitGroupsV3Onegroup.R")
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_alpha_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_alpha_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverseTemperatureTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
fit.RiskyNoMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.RiskyNoMeth.ex)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g2<-learningRateTable(fit.RiskyNoMeth.ex)
source("fitGroupsV3Onegroup.R")
learningRateTable<-function(f){rbind(
data.table(
mean=f$mu_alpha_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_alpha_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
inverseTemperatureTable<-function(f){rbind(
data.table(
mean=f$mu_beta_rew,
variance=f$sigma[,1,2],mode="reward",Group="RiskyMeth"),
data.table(mean=f$mu_beta_pun,
variance=f$sigma[,2,2],
mode="punishment",Group="RiskyMeth"))
}
fit.RiskyNoMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=2, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyNoMeth.ex<-rstan::extract(fit.RiskyNoMeth$fit)
rm(fit.RiskyNoMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g2<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g2<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
fit.RiskyMeth<-lookupOrRunFit(run=c(1,2),groups_to_fit=3, model_to_use="double_update_rp_repeated_runs",includeSubjGroup = FALSE,
rp=c(REVERSAL_LEARNING_REWARD,REVERSAL_LEARNING_PUNISHMENT),
model_rp_separately=TRUE,model_runs_separately = TRUE, include_pain=FALSE)
fit.RiskyMeth.ex<-rstan::extract(fit.RiskyMeth$fit)
rm(fit.RiskyMeth)#these are large files; let's not keep them in memory where unnecessary.
learning.rate.estimate.g3<-learningRateTable(fit.RiskyNoMeth.ex)
inverse.temperature.estimate.g3<-inverseTemperatureTable(fit.RiskyNoMeth.ex)
learning.rate.estimate<-rbind(learning.rate.estimate.g2,learning.rate.estimate.g3)
inverse.temperature.estimate<-rbind(inverse.temperature.estimate.g2,inverse.temperature.estimate.g3)
ggplot(learning.rate.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level learning rate and variance for reward and punishment\n(Both Runs)")
ggplot(inverse.temperature.estimate,aes(x=mean,y=variance,colour=Group))+geom_point()+
facet_grid(.~mode)+
labs(title="Posterior group-level inverse temperature and variance for reward and punishment\n(Both Runs)")
